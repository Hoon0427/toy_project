{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/@omicro03/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC-nlp-9%EC%9D%BC%EC%B0%A8-lda-%EC%8B%A4%EC%8A%B5-f6392e1ca958"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lda\n",
    "import keras\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/ekim_reverse/study/Python.study/toy_project/online_news_test.csv')\n",
    "vocab = pd.read_csv('/home/ekim_reverse/study/Python.study/toy_project/stop_words.csv', encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fetch_20newsgroups(shuffle = True, random_state = 1,\n",
    "                            remove = ('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "document=dataset.data\n",
    "news_df = pd.DataFrame({'document' : document})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 과정\n",
    "news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w) > 3]))\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 처리 및 토큰화\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "tokenized_doc = news_df['clean_doc'].apply(lambda x : x.split())\n",
    "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(tokenized_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in tokenized_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(52, 1),\n",
       " (55, 1),\n",
       " (56, 1),\n",
       " (57, 1),\n",
       " (58, 1),\n",
       " (59, 1),\n",
       " (60, 1),\n",
       " (61, 1),\n",
       " (62, 1),\n",
       " (63, 1),\n",
       " (64, 1),\n",
       " (65, 1),\n",
       " (66, 2),\n",
       " (67, 1),\n",
       " (68, 1),\n",
       " (69, 1),\n",
       " (70, 1),\n",
       " (71, 2),\n",
       " (72, 1),\n",
       " (73, 1),\n",
       " (74, 1),\n",
       " (75, 1),\n",
       " (76, 1),\n",
       " (77, 1),\n",
       " (78, 2),\n",
       " (79, 1),\n",
       " (80, 1),\n",
       " (81, 1),\n",
       " (82, 1),\n",
       " (83, 1),\n",
       " (84, 1),\n",
       " (85, 2),\n",
       " (86, 1),\n",
       " (87, 1),\n",
       " (88, 1),\n",
       " (89, 1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'faith'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary[66]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65284"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.021*\"price\" + 0.016*\"sale\" + 0.014*\"offer\" + 0.013*\"shipping\"')\n",
      "(1, '0.013*\"gordon\" + 0.012*\"pitt\" + 0.011*\"soon\" + 0.011*\"surrender\"')\n",
      "(2, '0.008*\"earth\" + 0.007*\"cover\" + 0.007*\"orbit\" + 0.006*\"moon\"')\n",
      "(3, '0.031*\"wire\" + 0.018*\"ground\" + 0.018*\"neutral\" + 0.016*\"panel\"')\n",
      "(4, '0.011*\"printer\" + 0.009*\"auto\" + 0.008*\"sony\" + 0.006*\"insurance\"')\n",
      "(5, '0.013*\"government\" + 0.007*\"state\" + 0.007*\"israel\" + 0.006*\"president\"')\n",
      "(6, '0.010*\"people\" + 0.010*\"said\" + 0.007*\"armenian\" + 0.006*\"armenians\"')\n",
      "(7, '0.019*\"drive\" + 0.016*\"thanks\" + 0.015*\"card\" + 0.013*\"anyone\"')\n",
      "(8, '0.021*\"simms\" + 0.016*\"plastic\" + 0.014*\"navy\" + 0.013*\"mask\"')\n",
      "(9, '0.008*\"filename\" + 0.007*\"david\" + 0.006*\"article\" + 0.006*\"picture\"')\n",
      "(10, '0.014*\"evidence\" + 0.013*\"science\" + 0.011*\"printf\" + 0.011*\"exist\"')\n",
      "(11, '0.019*\"braves\" + 0.014*\"master\" + 0.013*\"slave\" + 0.011*\"cubs\"')\n",
      "(12, '0.038*\"file\" + 0.027*\"output\" + 0.023*\"entry\" + 0.018*\"program\"')\n",
      "(13, '0.019*\"game\" + 0.018*\"team\" + 0.012*\"year\" + 0.012*\"games\"')\n",
      "(14, '0.018*\"chip\" + 0.018*\"encryption\" + 0.015*\"keys\" + 0.013*\"clipper\"')\n",
      "(15, '0.021*\"would\" + 0.013*\"think\" + 0.012*\"like\" + 0.012*\"know\"')\n",
      "(16, '0.011*\"window\" + 0.010*\"version\" + 0.010*\"file\" + 0.010*\"windows\"')\n",
      "(17, '0.008*\"power\" + 0.008*\"bike\" + 0.006*\"back\" + 0.006*\"speed\"')\n",
      "(18, '0.015*\"space\" + 0.010*\"information\" + 0.008*\"mail\" + 0.007*\"also\"')\n",
      "(19, '0.017*\"jesus\" + 0.011*\"christian\" + 0.010*\"bible\" + 0.008*\"church\"')\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "NUM_TOPICS = 20\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
